{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448a4a12-3ec8-4d70-b61b-463ef0acd776",
   "metadata": {},
   "source": [
    "# HW 1: Applying the ML pipeline\n",
    "\n",
    "### COSC 410B: Spring 2025, Colgate University\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6320f14c-f72e-42cb-8308-82484dfe7fa4",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In this HW you will apply the ML pipeline by using KNN models to predict student exam factors using several different features. Concretely, you will be working with the [Student Performance Factors](https://www.kaggle.com/datasets/lainguyn123/student-performance-factors?resource=download) on Kaggle. \n",
    "\n",
    "**Your task is to predict exam scores in this dataset as well as you can.**  \n",
    "\n",
    "#### The ML Pipeline\n",
    "\n",
    "1. Preprocess the data and split it into train and test (no need for validation set because we will use k-fold cross-validation). For this homework use 80% of the data for training, and 20% for evaluation. \n",
    "2. Exploring the training data: What are the input features you could use? What features do you want to use and explore? Why? The answers to this can either be theory driven or data-driven. \n",
    "3. Explore different features and hyperparameters with k-fold cross validation. Pick the best model (i.e., feature set and hyperparameter combination)\n",
    "4. Evaluate the best model and discuss the results.\n",
    "\n",
    "You should structure the code and writing in this notebook in format that makes it easy to follow along with your thought process and argument. \n",
    "\n",
    "\n",
    "#### Questions to answer before you start\n",
    "* Will you use KNN-regression or KNN-classification? Why? \n",
    "* How will you handle non-numerical columns?\n",
    "* You will notice that many of the columns are on different scales. Why is this a problem for KNN models? How can you handle this? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c3e4b-2324-4458-a8cc-2e0eefc36d0c",
   "metadata": {},
   "source": [
    "**[WRITE YOUR ANSWERS HERE]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c66fcae-209a-4fbb-80e3-e33b55bdca5e",
   "metadata": {},
   "source": [
    "## Your report\n",
    "\n",
    "Add code and markdown chunks for your data analysis report here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470298a0",
   "metadata": {},
   "source": [
    "\n",
    "First, we're going to get the folded data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11242111-3da3-4fd4-acc2-b85799942006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import KNN\n",
    "import util\n",
    "from importlib import reload\n",
    "reload(util)\n",
    "reload(KNN)\n",
    "\n",
    "split_data = util.splitData(\"StudentPerformanceFactors.csv\", 7)\n",
    "myKnn = KNN.KNN(\"Classification\", 5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa4406",
   "metadata": {},
   "source": [
    "Now we're going to run the analysis on each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9c1a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m true \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(split_data[i])):\n\u001b[0;32m---> 25\u001b[0m     pred\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmyKnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m     true\u001b[38;5;241m.\u001b[39mappend(split_data[i][j][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m## now let's compare values and get an f-score\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/cosc410/hw/hw01/KNN.py:70\u001b[0m, in \u001b[0;36mKNN.predict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY[minIndex]\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m                 \u001b[43mdistances\u001b[49m\u001b[43m[\u001b[49m\u001b[43mminIndex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m super_large_number\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mode[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegression\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(4)\n",
    "\n",
    "\n",
    "cumulative_fscores = 0\n",
    "for i in range(len(split_data)):\n",
    "    ## for each fold, where the ith index of split_data is the test data\n",
    "    x_labels = []\n",
    "    y_values = []\n",
    "    for j in range(len(split_data)):\n",
    "\n",
    "        ## collecting training data from [not test] arrays\n",
    "        if (i != j):\n",
    "            for k in range(len(split_data[j])): \n",
    "                x_labels.append(split_data[j][k][:-1])\n",
    "                y_values.append(split_data[j][k][-1])\n",
    "\n",
    "    ## now we have x_labels and y_values, so let's fit\n",
    "    myKnn.fit(x_labels, y_values)\n",
    "\n",
    "    ## now let's test on the test fold\n",
    "    pred = []\n",
    "    true = []\n",
    "    for j in range(len(split_data[i])):\n",
    "        pred.append(myKnn.predict(split_data[i][j][:-1]))\n",
    "        true.append(split_data[i][j][-1])\n",
    "    \n",
    "    ## now let's compare values and get an f-score\n",
    "    pred = np.array(pred)\n",
    "    true = np.array(true)\n",
    "    evaluation = util.fscore(pred, true, 1)\n",
    "    cumulative_fscores += evaluation\n",
    "\n",
    "## time to average cumulative_fscores\n",
    "print(\"Average fscore\", str(cumulative_fscores/len(split_data)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
